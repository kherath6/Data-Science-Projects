{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import dependancies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'structured_data_classifier',\n",
       " 'Categorical Summary.docx',\n",
       " 'Project Draft 1.ipynb',\n",
       " 'Data Sets',\n",
       " 'healthcareClanedTrain3.csv',\n",
       " 'healthcareClanedTrain2.csv',\n",
       " 'Modeling .ipynb',\n",
       " 'Decision and Naives - healthcareClanedTrain3.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'MIS 776 Group Project.pdf',\n",
       " '11.16.2020 Dannica Update.ipynb',\n",
       " 'healthcareClanedTrain.csv',\n",
       " 'Ryan Script.ipynb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hosp_code</th>\n",
       "      <th>hosp_type</th>\n",
       "      <th>city_code</th>\n",
       "      <th>hosp_region</th>\n",
       "      <th>rooms_available</th>\n",
       "      <th>department</th>\n",
       "      <th>ward_type</th>\n",
       "      <th>ward_code</th>\n",
       "      <th>bed_grade</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>severity</th>\n",
       "      <th>num_visitors</th>\n",
       "      <th>age</th>\n",
       "      <th>deposit</th>\n",
       "      <th>stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>31397</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4911</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>31397</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5954</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>31397</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4745</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>31397</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7272</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>31397</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5558</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hosp_code  hosp_type  city_code  hosp_region  rooms_available  department  \\\n",
       "0          8          0          3            0                3           0   \n",
       "1          2          0          5            0                2           0   \n",
       "2         10          1          1            1                2           1   \n",
       "3         26          2          2            2                2           0   \n",
       "4         26          2          2            2                2           0   \n",
       "\n",
       "   ward_type  ward_code  bed_grade  patient_id  admission_type  severity  \\\n",
       "0          0          0          2       31397               0         0   \n",
       "1          1          0          2       31397               1         0   \n",
       "2          1          1          2       31397               1         0   \n",
       "3          0          2          2       31397               1         0   \n",
       "4          1          2          2       31397               1         0   \n",
       "\n",
       "   num_visitors  age  deposit  stay  \n",
       "0             2    5     4911     0  \n",
       "1             2    5     5954     4  \n",
       "2             2    5     4745     3  \n",
       "3             2    5     7272     4  \n",
       "4             2    5     5558     4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Load the dataset \n",
    "\n",
    "health = pd.read_csv('healthcareClanedTrain3.csv')\n",
    "health.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hosp_code', 'hosp_type', 'city_code', 'hosp_region', 'rooms_available',\n",
       "       'department', 'ward_type', 'ward_code', 'bed_grade', 'patient_id',\n",
       "       'admission_type', 'severity', 'num_visitors', 'age', 'deposit', 'stay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define X and y variables \n",
    "X = health.drop('stay', axis=1)\n",
    "y = health.stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hosp_code</th>\n",
       "      <th>hosp_type</th>\n",
       "      <th>city_code</th>\n",
       "      <th>hosp_region</th>\n",
       "      <th>rooms_available</th>\n",
       "      <th>department</th>\n",
       "      <th>ward_type</th>\n",
       "      <th>ward_code</th>\n",
       "      <th>bed_grade</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>severity</th>\n",
       "      <th>num_visitors</th>\n",
       "      <th>age</th>\n",
       "      <th>deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>31397</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>31397</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>31397</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>31397</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>31397</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hosp_code  hosp_type  city_code  hosp_region  rooms_available  department  \\\n",
       "0          8          0          3            0                3           0   \n",
       "1          2          0          5            0                2           0   \n",
       "2         10          1          1            1                2           1   \n",
       "3         26          2          2            2                2           0   \n",
       "4         26          2          2            2                2           0   \n",
       "\n",
       "   ward_type  ward_code  bed_grade  patient_id  admission_type  severity  \\\n",
       "0          0          0          2       31397               0         0   \n",
       "1          1          0          2       31397               1         0   \n",
       "2          1          1          2       31397               1         0   \n",
       "3          0          2          2       31397               1         0   \n",
       "4          1          2          2       31397               1         0   \n",
       "\n",
       "   num_visitors  age  deposit  \n",
       "0             2    5     4911  \n",
       "1             2    5     5954  \n",
       "2             2    5     4745  \n",
       "3             2    5     7272  \n",
       "4             2    5     5558  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the data\n",
    "\n",
    "##from sklearn.model_selection import train_test_split\n",
    "\n",
    "##X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reshape the target data to include the levels \n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y = to_categorical(y)\n",
    "\n",
    "print('y shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a neural network with the entire dataset \n",
    "   **without standardizing any variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating Neural Network \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input shape\n",
    "input_shape = X.shape[1]\n",
    "\n",
    "# Instantiate the Sequential model \n",
    "nn1 = Sequential()\n",
    "\n",
    "# Add Layers \n",
    "nn1.add(Dense(32, activation='relu',input_shape=(input_shape,)))\n",
    "nn1.add(Dense(16, activation='relu'))\n",
    "nn1.add(BatchNormalization())\n",
    "nn1.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add output layer \n",
    "nn1.add(Dense(11, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compile the model \n",
    "nn1.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check model summary\n",
    "nn1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the model \n",
    "batch_size = 25\n",
    "n_epochs = 15\n",
    "\n",
    "hist = nn1.fit(X, y, epochs=n_epochs, batch_size=batch_size, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(np.log(hist.history['loss']), label='Training Loss')\n",
    "ax.plot(np.log(hist.history['val_loss']), label='Validation Loss')\n",
    "ax.set_title(\"log(Loss) vs. epochs\", fontsize=15)\n",
    "ax.set_xlabel(\"epoch number\", fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Both Training Loss and Validation Loss seem to decline at every epoch. \n",
    "- Training loss is a bit lower than validation loss (not unusual). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(np.log(hist.history['accuracy']), label='Training Accuracy')\n",
    "ax.plot(np.log(hist.history['val_accuracy']), label='Validation Accuracy')\n",
    "ax.set_title(\"Accuracy vs. epochs\", fontsize=15)\n",
    "ax.set_xlabel(\"epoch number\", fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The model is not performing well. Both accuracy and vaidation accuracy are on 30%. The model needs to be improved a lot.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a new model with standardized numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X.copy()\n",
    "y1 = health.stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standardize the numerical data \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numeraical_data = ['rooms_available','num_visitors','deposit', 'patient_id']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X1.loc[:,numeraical_data] = scaler.fit_transform(X1[numeraical_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reshape the target data to include the levels \n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y1 = to_categorical(y1)\n",
    "\n",
    "print('y1 shape: ', y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new neural network \n",
    "# Define input shape\n",
    "input_shape = X1.shape[1]\n",
    "\n",
    "# Instantiate the Sequential model \n",
    "nn2 = Sequential()\n",
    "\n",
    "# Add Layers \n",
    "nn2.add(Dense(128, activation='relu',input_shape=(input_shape,)))\n",
    "nn2.add(BatchNormalization())\n",
    "nn2.add(Dense(64, activation='relu'))\n",
    "nn2.add(Dense(32, activation='relu'))\n",
    "nn2.add(Dense(16, activation='relu'))\n",
    "nn2.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add output layer \n",
    "nn2.add(Dense(11, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compile the model \n",
    "nn2.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "nn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the model \n",
    "batch_size = 50\n",
    "n_epochs = 20\n",
    "\n",
    "hist = nn2.fit(X1, y1, epochs=n_epochs, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(np.log(hist.history['loss']), label='Training Loss')\n",
    "ax.plot(np.log(hist.history['val_loss']), label='Validation Loss')\n",
    "ax.set_title(\"log(Loss) vs. epochs\", fontsize=15)\n",
    "ax.set_xlabel(\"epoch number\", fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(np.log(hist.history['accuracy']), label='Training Accuracy')\n",
    "ax.plot(np.log(hist.history['val_accuracy']), label='Validation Accuracy')\n",
    "ax.set_title(\"Accuracy vs. epochs\", fontsize=15)\n",
    "ax.set_xlabel(\"epoch number\", fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is a massive gap between training loss and validation loss. \n",
    "- Both training loss and valoidation loss seem to decline. \n",
    "- Both training and validation accuracies did increase. \n",
    "- After 17 epochs validation accuracy seem to start dipping. \n",
    "- The overfitting is getting better. \n",
    "\n",
    "#### The model needs to be much more improved. Accuracy scores are stil in the 30s and loss is high. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train a new network with changed architecture \n",
    "\n",
    "## Create a new neural network \n",
    "# Define input shape\n",
    "input_shape = X1.shape[1]\n",
    "\n",
    "# Instantiate the Sequential model \n",
    "nn3 = Sequential()\n",
    "\n",
    "# Add Layers \n",
    "nn3.add(Dense(64, activation='relu', input_shape=(input_shape,)))\n",
    "nn3.add(Dense(32, activation='relu'))\n",
    "nn3.add(Dense(16, activation='relu'))\n",
    "nn3.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add output layer \n",
    "nn3.add(Dense(11, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compile the model \n",
    "nn3.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "nn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the model \n",
    "batch_size = 50\n",
    "n_epochs = 20\n",
    "\n",
    "hist2 = nn3.fit(X1, y1, epochs=n_epochs, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(np.log(hist2.history['loss']), label='Training Loss')\n",
    "ax.plot(np.log(hist2.history['val_loss']), label='Validation Loss')\n",
    "ax.set_title(\"log(Loss) vs. epochs\", fontsize=15)\n",
    "ax.set_xlabel(\"epoch number\", fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(hist2.history['accuracy'], label='Training Accuracy')\n",
    "ax.plot(hist2.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax.set_title(\"Accuracy vs. epochs\", fontsize=15)\n",
    "ax.set_xlabel(\"epoch number\", fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Both the accuracy and loss seem to have been improved a lot. \n",
    "- However accuracy is still below 40%\n",
    "- The model needs to be much more improved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrain a new network with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from tensorflow import keras\n",
    "\n",
    "X1, y1 = shuffle(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train a new network with changed architecture \n",
    "\n",
    "## Create a new neural network \n",
    "# Define input shape\n",
    "input_shape = X1.shape[1]\n",
    "\n",
    "# Instantiate the Sequential model \n",
    "nn4 = Sequential()\n",
    "\n",
    "# Add Layers \n",
    "nn4.add(Dense(32, activation='relu',kernel_initializer='he_uniform', input_shape=(input_shape,)))\n",
    "nn4.add(Dense(32, activation='relu'))\n",
    "nn4.add(Dense(32, activation='relu'))\n",
    "nn4.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add output layer \n",
    "nn4.add(Dense(11, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compile the model\n",
    "\n",
    "# Define a custom optimizer \n",
    "opt = keras.optimizers.Adam(lr=0.01)\n",
    "nn4.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=opt)\n",
    "\n",
    "nn4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the model \n",
    "batch_size = 100\n",
    "n_epochs = 20\n",
    "\n",
    "hist3 = nn4.fit(X1, y1, epochs=n_epochs, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(np.log(hist3.history['loss']), label='Training Loss')\n",
    "ax.plot(np.log(hist3.history['val_loss']), label='Validation Loss')\n",
    "ax.set_title(\"log(Loss) vs. epochs\", fontsize=15)\n",
    "ax.set_xlabel(\"epoch number\", fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(hist3.history['accuracy'], label='Training Accuracy')\n",
    "ax.plot(hist3.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax.set_title(\"Accuracy vs. epochs\", fontsize=15)\n",
    "ax.set_xlabel(\"epoch number\", fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Still no improvement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale all features and retrain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new datasets\n",
    "\n",
    "X2 = X.copy()\n",
    "y2 = health.stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standardize the numerical data \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X2.loc[:,:] = scaler.fit_transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = to_categorical(y2)\n",
    "\n",
    "print('y2 shape: ', y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new neural network \n",
    "# Define input shape\n",
    "input_shape = X2.shape[1]\n",
    "\n",
    "# Instantiate the Sequential model \n",
    "nn5 = Sequential()\n",
    "\n",
    "# Add Layers \n",
    "nn5.add(Dense(32, activation='relu',kernel_initializer='he_uniform', input_shape=(input_shape,)))\n",
    "nn5.add(Dense(32, activation='relu'))\n",
    "nn5.add(Dense(32, activation='relu'))\n",
    "nn5.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add output layer \n",
    "nn5.add(Dense(11, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compile the model\n",
    "\n",
    "# Define a custom optimizer \n",
    "opt = keras.optimizers.Adam(lr=0.01)\n",
    "nn5.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=opt)\n",
    "\n",
    "nn5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the model \n",
    "batch_size = 100\n",
    "n_epochs = 20\n",
    "\n",
    "hist4 = nn5.fit(X2, y2, epochs=n_epochs, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The results are much worse.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data \n",
    "X2, y2 = shuffle(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new neural network \n",
    "# Define input shape\n",
    "input_shape = X2.shape[1]\n",
    "\n",
    "# Instantiate the Sequential model \n",
    "nn6 = Sequential()\n",
    "\n",
    "# Add Layers \n",
    "nn6.add(Dense(64, activation='relu',kernel_initializer='he_uniform', input_shape=(input_shape,)))\n",
    "nn6.add(Dense(32, activation='relu'))\n",
    "nn6.add(Dense(16, activation='relu'))\n",
    "nn6.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add output layer \n",
    "nn6.add(Dense(11, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compile the model\n",
    "\n",
    "# Define a custom optimizer \n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "nn6.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=opt)\n",
    "\n",
    "nn6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the model \n",
    "batch_size = 100\n",
    "n_epochs = 20\n",
    "\n",
    "hist5 = nn6.fit(X2, y2, epochs=n_epochs, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model performs worse than before. Both the accuracy and  the loss values are not optimal. \n",
    "- **Standardizing all values seems to be less effective**\n",
    "- **Standardizing only the  numeric values seem to bring better results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescale all the data using a Robust Scaler to deal with outliers and retrain a new model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new datasets\n",
    "\n",
    "X4 = X.copy()\n",
    "y4 = health.stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standardize the numerical data using a robust scaler \n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X4.loc[:,:] = scaler.fit_transform(X4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y4 = to_categorical(y4)\n",
    "\n",
    "print('y4 shape: ', y4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new neural network \n",
    "# Define input shape\n",
    "input_shape = X4.shape[1]\n",
    "\n",
    "# Instantiate the Sequential model \n",
    "nn7 = Sequential()\n",
    "\n",
    "# Add Layers \n",
    "nn7.add(Dense(64, activation='relu', input_shape=(input_shape,)))\n",
    "nn7.add(Dense(32, activation='relu'))\n",
    "nn7.add(Dense(16, activation='relu'))\n",
    "nn7.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add output layer \n",
    "nn7.add(Dense(11, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compile the model\n",
    "\n",
    "# Define a custom optimizer \n",
    "#opt = keras.optimizers.Adam(lr=0.001)\n",
    "nn7.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "nn7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the model \n",
    "batch_size = 75\n",
    "n_epochs = 20\n",
    "\n",
    "hist6 = nn7.fit(X4, y4, epochs=n_epochs, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(np.log(hist6.history['loss']), label='Training Loss')\n",
    "ax.plot(np.log(hist6.history['val_loss']), label='Validation Loss')\n",
    "ax.set_title(\"log(Loss) vs. epochs\", fontsize=15)\n",
    "ax.set_xlabel(\"epoch number\", fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(hist6.history['accuracy'], label='Training Accuracy')\n",
    "ax.plot(hist6.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax.set_title(\"Accuracy vs. epochs\", fontsize=15)\n",
    "ax.set_xlabel(\"epoch number\", fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the robust scaler but only scale the numeric columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new datasets\n",
    "\n",
    "X5 = X.copy()\n",
    "y5 = health.stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standardize the numerical data using a robust scaler \n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "numerical_data = ['rooms_available','num_visitors','deposit', 'patient_id']\n",
    "\n",
    "scalerR = RobustScaler()\n",
    "X5.loc[:,numerical_data] = scalerR.fit_transform(X5[numerical_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape target variable\n",
    "y5 = to_categorical(y5)\n",
    "\n",
    "print('y5 shape: ', y5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new neural network \n",
    "# Define input shape\n",
    "input_shape = X5.shape[1]\n",
    "\n",
    "# Instantiate the Sequential model \n",
    "nn8 = Sequential()\n",
    "\n",
    "# Add Layers \n",
    "nn8.add(Dense(64, activation='relu', input_shape=(input_shape,)))\n",
    "nn8.add(Dense(32, activation='relu'))\n",
    "nn8.add(Dense(16, activation='relu'))\n",
    "nn8.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add output layer \n",
    "nn8.add(Dense(11, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compile the model\n",
    "\n",
    "# Define a custom optimizer \n",
    "#opt = keras.optimizers.Adam(lr=0.001)\n",
    "nn8.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "nn8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the model \n",
    "batch_size = 75\n",
    "n_epochs = 20\n",
    "\n",
    "hist7 = nn8.fit(X5, y5, epochs=n_epochs, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(np.log(hist7.history['loss']), label='Training Loss')\n",
    "ax.plot(np.log(hist7.history['val_loss']), label='Validation Loss')\n",
    "ax.set_title(\"log(Loss) vs. epochs\", fontsize=15)\n",
    "ax.set_xlabel(\"epoch number\", fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(hist7.history['accuracy'], label='Training Accuracy')\n",
    "ax.plot(hist7.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax.set_title(\"Accuracy vs. epochs\", fontsize=15)\n",
    "ax.set_xlabel(\"epoch number\", fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retarain with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data \n",
    "X5, y5 = shuffle(X5,y5)\n",
    "\n",
    "print(X5.shape)\n",
    "print(y5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the X5 dataframe into floats\n",
    "\n",
    "X5 = X5.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new neural network \n",
    "# Define input shape\n",
    "input_shape = X5.shape[1]\n",
    "\n",
    "# Instantiate the Sequential model \n",
    "nn9 = Sequential()\n",
    "\n",
    "# Add Layers \n",
    "nn9.add(Dense(32, activation='relu', input_shape=(input_shape,)))\n",
    "nn9.add(Dense(16, activation='relu'))\n",
    "\n",
    "\n",
    "# Add output layer \n",
    "nn9.add(Dense(11, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compile the model\n",
    "\n",
    "# Define a custom optimizer \n",
    "#opt = keras.optimizers.Adam(lr=0.001)\n",
    "nn9.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "nn9.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the model \n",
    "batch_size = 75\n",
    "n_epochs = 20\n",
    "\n",
    "hist8 = nn9.fit(X5, y5, epochs=n_epochs, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(np.log(hist8.history['loss']), label='Training Loss')\n",
    "ax.plot(np.log(hist8.history['val_loss']), label='Validation Loss')\n",
    "ax.set_title(\"log(Loss) vs. epochs\", fontsize=15)\n",
    "ax.set_xlabel(\"epoch number\", fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(hist8.history['accuracy'], label='Training Accuracy')\n",
    "ax.plot(hist8.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax.set_title(\"Accuracy vs. epochs\", fontsize=15)\n",
    "ax.set_xlabel(\"epoch number\", fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
